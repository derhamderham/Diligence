//
//  AIModels.swift
//  Diligence
//
//  Data models for AI provider selection and configuration
//

import Foundation
import SwiftUI

// MARK: - AI Provider

/// Supported AI service providers for email analysis and task generation
///
/// Diligence supports multiple AI backends to give users flexibility in
/// choosing between privacy-focused on-device processing or customizable
/// local LLM servers.
///
/// ## Topics
///
/// ### Cases
/// - ``appleIntelligence``
/// - ``janAI``
///
/// ### Properties
/// - ``displayName``
/// - ``icon``
/// - ``description``
public enum AIProvider: String, CaseIterable, Identifiable, Codable {
    /// Apple's on-device AI (FoundationModels framework)
    ///
    /// Provides fast, private AI processing using Apple's on-device models.
    /// Requires compatible hardware and software (macOS Sequoia or later).
    case appleIntelligence = "apple"
    
    /// Jan.ai local LLM server
    ///
    /// Connects to a locally-running Jan.ai instance for customizable
    /// AI processing with various open-source models.
    case janAI = "jan"
    
    public var id: Self { self }
    
    /// Human-readable name of the provider
    public var displayName: String {
        switch self {
        case .appleIntelligence:
            return "Apple Intelligence"
        case .janAI:
            return "Jan.ai (Local)"
        }
    }
    
    /// SF Symbol icon representing the provider
    public var icon: String {
        switch self {
        case .appleIntelligence:
            return "apple.logo"
        case .janAI:
            return "server.rack"
        }
    }
    
    /// Detailed description of the provider
    public var description: String {
        switch self {
        case .appleIntelligence:
            return "On-device Apple Intelligence (Private & Fast)"
        case .janAI:
            return "Local Jan.ai server (Customizable)"
        }
    }
    
    /// Color associated with the provider for UI display
    public var color: Color {
        switch self {
        case .appleIntelligence:
            return .blue
        case .janAI:
            return .purple
        }
    }
}

// MARK: - AI Task Generation Request

/// Request model for generating tasks from emails using AI
///
/// Contains the email information and any user preferences for how
/// tasks should be generated.
struct AITaskGenerationRequest: Codable {
    /// Array of emails to analyze
    let emails: [EmailForAI]
    
    /// User preferences for task generation
    let preferences: TaskGenerationPreferences?
    
    /// Maximum number of tasks to generate
    let maxTasks: Int?
}

/// Simplified email representation for AI processing
struct EmailForAI: Codable {
    /// Email subject
    let subject: String
    
    /// Email sender
    let sender: String
    
    /// Email body (truncated if necessary)
    let body: String
    
    /// Received date
    let date: Date
    
    /// Whether the email has attachments
    let hasAttachments: Bool
}

/// User preferences for AI task generation
struct TaskGenerationPreferences: Codable {
    /// Include emails with attachments
    let includeAttachments: Bool
    
    /// Preferred due date strategy (e.g., "tomorrow", "next week")
    let dueDateStrategy: String?
    
    /// Whether to automatically assign tasks to sections
    let autoAssignSections: Bool
}

// MARK: - AI Task Generation Response

/// Response from AI task generation
///
/// Contains the generated tasks and any warnings or errors.
struct AITaskGenerationResponse: Codable {
    /// Array of tasks generated by the AI
    let tasks: [GeneratedTask]
    
    /// Warning messages (e.g., truncated emails, rate limits)
    let warnings: [String]?
    
    /// Whether the AI processing was successful
    let success: Bool
}

/// A task generated by AI from email content
struct GeneratedTask: Codable, Identifiable {
    /// Unique identifier
    let id: String
    
    /// Task title
    let title: String
    
    /// Task description
    let description: String
    
    /// Suggested due date
    let suggestedDueDate: Date?
    
    /// Source email ID
    let sourceEmailID: String?
    
    /// Confidence score (0.0 - 1.0) indicating how confident the AI is
    let confidence: Double?
    
    /// Suggested section or category
    let suggestedSection: String?
}

// MARK: - AI Service Status

/// Status of an AI service
///
/// Tracks availability, errors, and readiness of AI providers.
public enum AIServiceStatus: Equatable {
    /// Service is available and ready
    case available
    
    /// Service is unavailable (not installed, not configured, etc.)
    case unavailable
    
    /// Service is currently initializing
    case initializing
    
    /// Service encountered an error
    case error(String)
    
    /// Human-readable status text
    public var displayText: String {
        switch self {
        case .available:
            return "Available"
        case .unavailable:
            return "Unavailable"
        case .initializing:
            return "Initializing..."
        case .error(let message):
            return "Error: \(message)"
        }
    }
    
    /// Color representing the status
    public var color: NSColor {
        switch self {
        case .available:
            return .systemGreen
        case .unavailable:
            return .systemOrange
        case .initializing:
            return .systemYellow
        case .error:
            return .systemRed
        }
    }
    
    /// SF Symbol icon for the status
    public var icon: String {
        switch self {
        case .available:
            return "checkmark.circle.fill"
        case .unavailable:
            return "xmark.circle"
        case .initializing:
            return "clock"
        case .error:
            return "exclamationmark.triangle.fill"
        }
    }
}

// MARK: - LLM Configuration

/// Configuration for LLM (Language Model) parameters
///
/// Controls how the AI generates responses, including creativity,
/// response length, and other model parameters.
struct LLMRequestConfiguration: Codable {
    /// Temperature (0.0 - 1.0): Controls randomness/creativity
    ///
    /// - 0.0: Deterministic, focused responses
    /// - 1.0: Creative, varied responses
    let temperature: Double
    
    /// Maximum number of tokens in the response
    let maxTokens: Int
    
    /// Top-p sampling threshold
    let topP: Double?
    
    /// Frequency penalty (-2.0 to 2.0)
    let frequencyPenalty: Double?
    
    /// Presence penalty (-2.0 to 2.0)
    let presencePenalty: Double?
    
    /// Model identifier to use
    let model: String?
    
    /// Default configuration for task generation
    static let taskGeneration = LLMRequestConfiguration(
        temperature: 0.7,
        maxTokens: 2048,
        topP: nil,
        frequencyPenalty: nil,
        presencePenalty: nil,
        model: nil
    )
    
    /// Default configuration for email summarization
    static let summarization = LLMRequestConfiguration(
        temperature: 0.3,
        maxTokens: 512,
        topP: nil,
        frequencyPenalty: nil,
        presencePenalty: nil,
        model: nil
    )
}

// MARK: - AI Analytics

/// Analytics data for tracking AI usage and performance
///
/// Useful for understanding AI effectiveness and debugging issues.
struct AIAnalytics: Codable {
    /// Total number of AI requests made
    var totalRequests: Int = 0
    
    /// Number of successful requests
    var successfulRequests: Int = 0
    
    /// Number of failed requests
    var failedRequests: Int = 0
    
    /// Total tasks generated by AI
    var totalTasksGenerated: Int = 0
    
    /// Average confidence score of generated tasks
    var averageConfidence: Double = 0.0
    
    /// Last request timestamp
    var lastRequestDate: Date?
    
    /// Current provider being used
    var currentProvider: AIProvider?
    
    /// Success rate (0.0 - 1.0)
    var successRate: Double {
        guard totalRequests > 0 else { return 0.0 }
        return Double(successfulRequests) / Double(totalRequests)
    }
}
